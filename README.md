# ğŸ” Databricks Insight Agent

> AI-powered analytics assistant for Databricks lakehouse with RAG-based context retrieval and intelligent SQL generation.

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/streamlit-1.28+-red.svg)](https://streamlit.io/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## âœ¨ Features

ğŸ§  **Intelligent Query Understanding** - Analyzes natural language to extract intent, filters, and metrics  
ğŸ”’ **Security First** - Multi-layer SQL injection protection and input validation  
ğŸ¯ **Schema-Aware SQL** - Generates queries only from known schema (no hallucinations)  
ğŸ” **RAG System** - FAISS-based semantic document retrieval for contextual insights  
ğŸ“Š **Delta Lake Integration** - Bronze/Silver/Gold medallion architecture  
âš¡ **Auto-Correction** - Detects and fixes SQL errors automatically  
ğŸ›¡ï¸ **Production Ready** - Error handling, rate limiting, and comprehensive logging

---

## ğŸš€ Quick Start

### 1. Setup
```bash
# Clone repository
git clone https://github.com/HasnainShafiq98/databricks-insight-agent.git
cd databricks-insight-agent

# Run automated setup
./scripts/quickstart.sh
```

### 2. Configure
```bash
# Copy environment template
cp config/.env.example .env

# Edit with your credentials
nano .env
```

### 3. Launch
```bash
# Streamlit UI (recommended)
streamlit run src/ui/app.py

# Or CLI
python src/ui/main.py

# Or run examples
python scripts/example_usage.py
```

---

## ğŸ“ Project Structure

```
databricks-insight-agent/
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ core/                     # Core application logic
â”‚   â”‚   â”œâ”€â”€ agent.py              # Main orchestrator
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                     # Data layer
â”‚   â”‚   â”œâ”€â”€ databricks_client.py  # SQL connector
â”‚   â”‚   â”œâ”€â”€ data_pipeline.py      # Delta table pipeline
â”‚   â”‚   â”œâ”€â”€ dbfs_integration.py   # DBFS storage
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ intelligence/             # AI/ML components
â”‚   â”‚   â”œâ”€â”€ sql_generator.py      # SQL generation
â”‚   â”‚   â”œâ”€â”€ sql_error_correction.py # Auto-correction
â”‚   â”‚   â”œâ”€â”€ context_retriever.py  # RAG system
â”‚   â”‚   â”œâ”€â”€ document_processor.py # Document chunking
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ security/                 # Security layer
â”‚   â”‚   â”œâ”€â”€ security.py           # Validation & rate limiting
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â””â”€â”€ ui/                       # User interfaces
â”‚       â”œâ”€â”€ app.py                # Streamlit web UI
â”‚       â”œâ”€â”€ main.py               # CLI interface
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ tests/                        # Test suite
â”‚   â”œâ”€â”€ test_core.py              # Core tests
â”‚   â”œâ”€â”€ examples.py               # Example queries
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ scripts/                      # Utility scripts
â”‚   â”œâ”€â”€ quickstart.sh             # Setup automation
â”‚   â””â”€â”€ example_usage.py          # Complete demos
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ README.md                 # This file
â”‚   â”œâ”€â”€ SETUP_GUIDE.md            # Setup instructions
â”‚   â”œâ”€â”€ DEVELOPMENT.md            # Development guide
â”‚   â”œâ”€â”€ GIT_WORKFLOW.md           # Git workflow
â”‚   â”œâ”€â”€ PROJECT_SUMMARY.md        # Implementation details
â”‚   â”œâ”€â”€ ARCHITECTURE.md           # System architecture
â”‚   â””â”€â”€ SECURITY.md               # Security guidelines
â”‚
â”œâ”€â”€ config/                       # Configuration
â”‚   â””â”€â”€ .env.example              # Environment template
â”‚
â”œâ”€â”€ data/                         # Data storage
â”‚   â”œâ”€â”€ csv/                      # Input CSV files
â”‚   â”œâ”€â”€ documents/                # Knowledge base
â”‚   â”œâ”€â”€ cache/                    # Local cache
â”‚   â””â”€â”€ logs/                     # Application logs
â”‚
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ .gitignore                    # Git ignore rules
â””â”€â”€ .env                          # Local config (not in git)
```

---

## ğŸ¯ Architecture

```
User Query
    â†“
Security Validation
    â†“
Intent Analysis
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SQL Mode    â”‚    â”‚ Context Mode â”‚    â”‚  Hybrid Mode â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                    â”‚
       â–¼                   â–¼                    â–¼
  SQL Generator      FAISS Search          Both Systems
       â”‚                   â”‚                    â”‚
       â–¼                   â”‚                    â”‚
  Databricks              â”‚                    â”‚
  Execution               â”‚                    â”‚
       â”‚                   â”‚                    â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                  Insight Generation
                           â”‚
                           â–¼
                    User Response
```

---

## ğŸ’¡ Usage Examples

### Basic Query
```python
"Show me total sales by region"
â†’ Generates SQL: SELECT region, SUM(amount) FROM sales GROUP BY region
â†’ Executes on Databricks
â†’ Returns insights
```

### Context Query
```python
"What is Customer Lifetime Value?"
â†’ Retrieves from knowledge base
â†’ Returns definition and formula
```

### Hybrid Query
```python
"Analyze our Q4 sales performance"
â†’ Runs SQL for Q4 data
â†’ Retrieves seasonality context
â†’ Combines both for comprehensive answer
```

---

## ğŸ” Security Features

âœ… **SQL Injection Prevention** - Multi-layer validation and sanitization  
âœ… **Schema Enforcement** - Only allows queries on known tables/columns  
âœ… **Rate Limiting** - Prevents abuse with configurable limits  
âœ… **Input Validation** - Strict validation of all user inputs  
âœ… **Query Length Limits** - Prevents resource exhaustion  
âœ… **Audit Logging** - Comprehensive logging of all operations

---

## ğŸ“Š Data Pipeline

### Medallion Architecture

**Bronze Layer** (Raw Data)
- Ingests CSV files as-is
- Adds ingestion metadata
- Minimal validation

**Silver Layer** (Cleaned Data)
- Data quality checks
- Type normalization
- Duplicate removal
- Schema validation

**Gold Layer** (Business Metrics)
- Aggregated KPIs
- Business-ready analytics
- Optimized for queries

---

## ğŸ› ï¸ Configuration

### Environment Variables

Key settings in `.env`:

```ini
# Databricks (Required)
DATABRICKS_SERVER_HOSTNAME=your-workspace.cloud.databricks.com
DATABRICKS_HTTP_PATH=/sql/1.0/warehouses/xxx
DATABRICKS_ACCESS_TOKEN=dapi...

# Optional
OPENAI_API_KEY=sk-...                  # Enhanced query understanding
FAISS_INDEX_PATH=./data/faiss_index.faiss
MAX_QUERY_LENGTH=10000
RATE_LIMIT_PER_MINUTE=60
```

See [config/.env.example](config/.env.example) for all options.

---

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=src --cov-report=html

# Run examples
python scripts/example_usage.py
```

---

## ğŸ“š Documentation

- **[Setup Guide](docs/SETUP_GUIDE.md)** - Complete installation and configuration
- **[Development Guide](docs/DEVELOPMENT.md)** - Architecture and dev workflow
- **[Git Workflow](docs/GIT_WORKFLOW.md)** - Version control best practices
- **[Project Summary](docs/PROJECT_SUMMARY.md)** - Implementation details
- **[Architecture](docs/ARCHITECTURE.md)** - System design
- **[Security](docs/SECURITY.md)** - Security guidelines

---

## ğŸ¤ Contributing

We follow a structured Git workflow:

1. Create feature branch: `git checkout -b feature/your-feature`
2. Make changes with descriptive commits
3. Create pull request to `dev` branch
4. After review, merge to `dev`
5. Periodically release from `dev` to `main`

See [Git Workflow Guide](docs/GIT_WORKFLOW.md) for details.

---

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ“ Credits

Built with:
- [Databricks](https://databricks.com/) - Data lakehouse platform
- [FAISS](https://github.com/facebookresearch/faiss) - Vector search
- [Streamlit](https://streamlit.io/) - Web UI framework
- [Sentence Transformers](https://www.sbert.net/) - Embeddings
- [Delta Lake](https://delta.io/) - Storage layer

---

## ğŸ“ Support

- **Documentation:** See [docs/](docs/) directory
- **Issues:** Open an issue on GitHub
- **Questions:** Check [SETUP_GUIDE.md](docs/SETUP_GUIDE.md)

---

## ğŸ—ºï¸ Roadmap

- [ ] Multi-table join support
- [ ] Advanced visualizations
- [ ] Query history and favorites
- [ ] Real-time data streaming
- [ ] Advanced ML query understanding
- [ ] Export to multiple formats

---

**Version:** 2.0.0  
**Status:** âœ… Production Ready  
**Last Updated:** January 11, 2026

---

Made with â¤ï¸ by the Databricks Insight Agent Team
